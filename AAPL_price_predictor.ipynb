{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JflbzNtjKBWK",
        "outputId": "9529399c-0e9e-4ef8-96d3-4c25b2ccfc4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.55)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.7)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance pandas matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFuMKcONTBHm",
        "outputId": "739329cd-1d97-441a-b242-2f86a8f150ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading Apple stock data from Yahoo Finance...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (11181, 5)\n",
            "Date range: 1980-12-12 00:00:00 to 2025-04-23 00:00:00\n",
            "Total days: 11181\n",
            "Total datapoints: 55905\n",
            "\n",
            "Data Preview:\n",
            "Price          Close      High       Low      Open     Volume\n",
            "Ticker          AAPL      AAPL      AAPL      AAPL       AAPL\n",
            "Date                                                         \n",
            "1980-12-12  0.098726  0.099155  0.098726  0.098726  469033600\n",
            "1980-12-15  0.093575  0.094005  0.093575  0.094005  175884800\n",
            "1980-12-16  0.086707  0.087136  0.086707  0.087136  105728000\n",
            "1980-12-17  0.088853  0.089282  0.088853  0.088853   86441600\n",
            "1980-12-18  0.091429  0.091858  0.091429  0.091429   73449600\n",
            "\n",
            "Missing values:\n",
            "Price   Ticker\n",
            "Close   AAPL      0\n",
            "High    AAPL      0\n",
            "Low     AAPL      0\n",
            "Open    AAPL      0\n",
            "Volume  AAPL      0\n",
            "dtype: int64\n",
            "\n",
            "Calculating technical indicators...\n",
            "Original features: 5\n",
            "Expanded features: 12\n",
            "Total datapoints after feature engineering: 134004\n",
            "\n",
            "Available features in the dataset:\n",
            "1. ('Close', 'AAPL')\n",
            "2. ('High', 'AAPL')\n",
            "3. ('Low', 'AAPL')\n",
            "4. ('Open', 'AAPL')\n",
            "5. ('Volume', 'AAPL')\n",
            "6. ('RSI_14', '')\n",
            "7. ('Day_of_Week', '')\n",
            "8. ('Month', '')\n",
            "9. ('Day_of_Month', '')\n",
            "10. ('Gap_Up', '')\n",
            "11. ('Gap_Down', '')\n",
            "12. ('Next_Day_Open', '')\n",
            "\n",
            "Preparing data for training...\n",
            "Applying MinMax scaling to features...\n",
            "Creating sequences with lookback period of 90 days...\n",
            "Sequence shape: (11077, 90, 11)\n",
            "Target shape: (11077,)\n",
            "Training set: (9969, 90, 11)\n",
            "Testing set: (1108, 90, 11)\n",
            "\n",
            "Data preparation complete! Files saved and ready for model training.\n",
            "Feature list saved to 'feature_list.txt'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Apple Stock Price Prediction - Data Preparation\n",
        "# This script downloads Apple stock data and prepares it for deep learning\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Download Apple's complete stock history\n",
        "print(\"Downloading Apple stock data from Yahoo Finance...\")\n",
        "aapl_data = yf.download(\"AAPL\", period=\"max\")\n",
        "\n",
        "# Display info about the dataset\n",
        "print(f\"Dataset shape: {aapl_data.shape}\")\n",
        "print(f\"Date range: {aapl_data.index.min()} to {aapl_data.index.max()}\")\n",
        "print(f\"Total days: {aapl_data.shape[0]}\")\n",
        "print(f\"Total datapoints: {aapl_data.shape[0] * aapl_data.shape[1]}\")\n",
        "\n",
        "# Preview the data\n",
        "print(\"\\nData Preview:\")\n",
        "print(aapl_data.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values:\")\n",
        "print(aapl_data.isnull().sum())\n",
        "\n",
        "# Calculate technical indicators\n",
        "print(\"\\nCalculating technical indicators...\")\n",
        "df = aapl_data.copy()\n",
        "\n",
        "# 1. RSI (14-day)\n",
        "delta = df['Close'].diff()\n",
        "gain = delta.where(delta > 0, 0)\n",
        "loss = -delta.where(delta < 0, 0)\n",
        "avg_gain = gain.rolling(window=14).mean()\n",
        "avg_loss = loss.rolling(window=14).mean()\n",
        "rs = avg_gain / avg_loss\n",
        "df['RSI_14'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "# 2. Add date-based features\n",
        "df['Day_of_Week'] = df.index.dayofweek\n",
        "df['Month'] = df.index.month\n",
        "df['Day_of_Month'] = df.index.day\n",
        "\n",
        "# 3. Price patterns - gaps\n",
        "df['Gap_Up'] = ((df['Open'] > df['Close'].shift(1)) * 1)\n",
        "df['Gap_Down'] = ((df['Open'] < df['Close'].shift(1)) * 1)\n",
        "\n",
        "# 4. Add our target variable - next day's opening price\n",
        "df['Next_Day_Open'] = df['Open'].shift(-1)\n",
        "\n",
        "# Remove rows with NaN values (from rolling calculations)\n",
        "df_clean = df.dropna()\n",
        "print(f\"Original features: {aapl_data.shape[1]}\")\n",
        "print(f\"Expanded features: {df.shape[1]}\")\n",
        "print(f\"Total datapoints after feature engineering: {df_clean.shape[0] * df_clean.shape[1]}\")\n",
        "\n",
        "# Show all features\n",
        "print(\"\\nAvailable features in the dataset:\")\n",
        "for i, col in enumerate(df_clean.columns):\n",
        "    print(f\"{i+1}. {col}\")\n",
        "\n",
        "# Prepare data for model training\n",
        "print(\"\\nPreparing data for training...\")\n",
        "\n",
        "# Define features and target\n",
        "X = df_clean.drop(['Next_Day_Open'], axis=1)\n",
        "y = df_clean['Next_Day_Open']\n",
        "\n",
        "# Feature scaling\n",
        "print(\"Applying MinMax scaling to features...\")\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Create sequences for time series prediction\n",
        "def create_sequences(X, y, time_steps=90):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        X_seq.append(X[i:i + time_steps])\n",
        "        y_seq.append(y[i + time_steps])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# Define sequence length (lookback period)\n",
        "sequence_length = 90  # Using 90 days of data to predict the next day\n",
        "\n",
        "print(f\"Creating sequences with lookback period of {sequence_length} days...\")\n",
        "X_seq, y_seq = create_sequences(X_scaled, y_scaled, sequence_length)\n",
        "\n",
        "print(f\"Sequence shape: {X_seq.shape}\")\n",
        "print(f\"Target shape: {y_seq.shape}\")\n",
        "\n",
        "# Train-test split (90-10)\n",
        "train_size = int(len(X_seq) * 0.9)\n",
        "X_train, X_test = X_seq[:train_size], X_seq[train_size:]\n",
        "y_train, y_test = y_seq[:train_size], y_seq[train_size:]\n",
        "\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Testing set: {X_test.shape}\")\n",
        "\n",
        "# Save processed data\n",
        "np.save('X_train.npy', X_train)\n",
        "np.save('y_train.npy', y_train)\n",
        "np.save('X_test.npy', X_test)\n",
        "np.save('y_test.npy', y_test)\n",
        "\n",
        "# Save scalers for later use\n",
        "import pickle\n",
        "with open('scaler_X.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler_X, f)\n",
        "with open('scaler_y.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler_y, f)\n",
        "\n",
        "print(\"\\nData preparation complete! Files saved and ready for model training.\")\n",
        "\n",
        "# Save the feature list for reference\n",
        "with open('feature_list.txt', 'w') as f:\n",
        "    for feature in X.columns:\n",
        "        f.write(f\"{feature}\\n\")\n",
        "\n",
        "print(\"Feature list saved to 'feature_list.txt'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhjtiOltix6U",
        "outputId": "7e1bc859-8cbc-42ab-9831-4978a6b63118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.04868987925314846\n",
            "Epoch 2, Loss: 0.0011635342291880918\n",
            "Epoch 3, Loss: 0.0004117288548607179\n",
            "Epoch 4, Loss: 0.00035937132452090736\n",
            "Epoch 5, Loss: 0.00037963872188275\n",
            "Epoch 6, Loss: 0.0004358791798156931\n",
            "Epoch 7, Loss: 0.0005886077004992657\n",
            "Epoch 8, Loss: 0.0006573829042071549\n",
            "Epoch 9, Loss: 0.000653965096786963\n",
            "Epoch 10, Loss: 0.0006347200696137196\n",
            "Epoch 11, Loss: 0.0006572611780659197\n",
            "Epoch 12, Loss: 0.0006952172251635019\n"
          ]
        }
      ],
      "source": [
        "#PyTorch implementation of the DNN\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Load prepared data\n",
        "X_train = np.load('X_train.npy')\n",
        "y_train = np.load('y_train.npy')\n",
        "X_test = np.load('X_test.npy')\n",
        "y_test = np.load('y_test.npy')\n",
        "\n",
        "# Define custom dataset class\n",
        "class StockDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx].unsqueeze(-1)\n",
        "\n",
        "# Create data loaders\n",
        "train_dataset = StockDataset(X_train, y_train)\n",
        "test_dataset = StockDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define model architecture\n",
        "class StockPredictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StockPredictor, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=X_train.shape[2], hidden_size=50, num_layers=2, batch_first=True)\n",
        "        self.bn = nn.BatchNorm1d(50)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.fc = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(2, x.size(0), 50).to(x.device)\n",
        "        c0 = torch.zeros(2, x.size(0), 50).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.bn(out[:, -1, :])\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Initialize model, optimizer, and loss function\n",
        "model = StockPredictor()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(200):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        X_batch, y_batch = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "train_mse = 0\n",
        "test_mse = 0\n",
        "with torch.no_grad():\n",
        "    for batch in train_loader:\n",
        "        X_batch, y_batch = batch\n",
        "        outputs = model(X_batch)\n",
        "        train_mse += criterion(outputs, y_batch).item() * len(X_batch)\n",
        "    train_mse /= len(train_loader.dataset)\n",
        "\n",
        "    for batch in test_loader:\n",
        "        X_batch, y_batch = batch\n",
        "        outputs = model(X_batch)\n",
        "        test_mse += criterion(outputs, y_batch).item() * len(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        test_loss += loss.item()\n",
        "    test_mse /= len(test_loader.dataset)\n",
        "\n",
        "print(f\"Train MSE: {train_mse:.4f}\")\n",
        "print(f\"Test MSE: {test_mse:.4f}\")\n",
        "print(f\"Test Loss: {test_loss / len(test_loader)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPn4orVLEEDh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}